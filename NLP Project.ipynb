{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf34a8a",
   "metadata": {},
   "source": [
    "## Part 1: Evaluating Student Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad6c60fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pratikhotchandani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/pratikhotchandani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e2a57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144293, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('/Users/pratikhotchandani/Downloads/Github/ArguSense/input/feedback-prize-2021/train.csv')\n",
    "print( train.shape )\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a01a836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train labels are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n",
       "       'Counterclaim', 'Rebuttal'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The train labels are:')\n",
    "train.discourse_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50dc4912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15594 train texts.\n"
     ]
    }
   ],
   "source": [
    "IDS = train.id.unique()\n",
    "print('There are',len(IDS),'train texts.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8737cf35",
   "metadata": {},
   "source": [
    "## STEPS:\n",
    "\n",
    "1. Tf-IDF and Naive Bayes\n",
    "2. Word embedding and XGBoost\n",
    "3. SOTA models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e3385",
   "metadata": {},
   "source": [
    "# 1. TF-IDF and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae003d4",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "becb1324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(review):\n",
    "    '''\n",
    "    Input:\n",
    "        review: a string containing a review.\n",
    "    Output:\n",
    "        review_cleaned: a processed review.\n",
    "    '''\n",
    "\n",
    "    # Lowercase the text\n",
    "    review = review.lower()\n",
    "\n",
    "    # Remove links using regular expressions\n",
    "    review = re.sub(r'http\\S+|www\\S+|https\\S+', '', review, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove punctuation\n",
    "    review = re.sub(r'[^\\w\\s]', '', review)\n",
    "\n",
    "    # Tokenize the text\n",
    "    words = nltk.word_tokenize(review)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Apply stemming using Porter Stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Reconstruct the cleaned review\n",
    "    review_cleaned = ' '.join(words)\n",
    "\n",
    "    return review_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a68f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data (implement preprocessing functions as needed)\n",
    "train['processed_text'] = train['discourse_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "985e533f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['processed_text'], train['discourse_type'], test_size=0.2)\n",
    "\n",
    "# Creating a pipeline for TF-IDF Vectorization and Naive Bayes Classifier\n",
    "NB_model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Training the model\n",
    "NB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb893a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "               Claim       0.48      0.76      0.59     10025\n",
      "Concluding Statement       0.90      0.02      0.04      2702\n",
      "        Counterclaim       1.00      0.01      0.02      1158\n",
      "            Evidence       0.57      0.75      0.65      9322\n",
      "                Lead       0.89      0.00      0.01      1793\n",
      "            Position       0.80      0.18      0.29      3037\n",
      "            Rebuttal       0.00      0.00      0.00       822\n",
      "\n",
      "            accuracy                           0.53     28859\n",
      "           macro avg       0.66      0.25      0.23     28859\n",
      "        weighted avg       0.62      0.53      0.45     28859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting and evaluating the model\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a5eef0",
   "metadata": {},
   "source": [
    "### Conducting an ablation study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127fe4a",
   "metadata": {},
   "source": [
    "#### A. K-Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bff422aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'configuration': {}, 'average_cv_score': 0.4970303759251258, 'std_dev': 0.0020973218090242847}\n",
      "{'configuration': {'tfidfvectorizer__max_df': 0.5, 'tfidfvectorizer__min_df': 1}, 'average_cv_score': 0.4970303759251258, 'std_dev': 0.0020973218090242847}\n",
      "{'configuration': {'tfidfvectorizer__max_df': 0.7, 'tfidfvectorizer__min_df': 2}, 'average_cv_score': 0.5078139940515963, 'std_dev': 0.0022976260090599083}\n",
      "{'configuration': {'tfidfvectorizer__ngram_range': (1, 2)}, 'average_cv_score': 0.5042448346827123, 'std_dev': 0.0031593764664926373}\n",
      "{'configuration': {'tfidfvectorizer__ngram_range': (1, 3)}, 'average_cv_score': 0.4965868160980797, 'std_dev': 0.004826271403941038}\n",
      "{'configuration': {'multinomialnb__alpha': 0.5}, 'average_cv_score': 0.5194638750497347, 'std_dev': 0.0026019786773325954}\n",
      "{'configuration': {'multinomialnb__alpha': 1.0}, 'average_cv_score': 0.4965868160980797, 'std_dev': 0.004826271403941038}\n",
      "{'configuration': {'tfidfvectorizer__ngram_range': (1, 2), 'multinomialnb__alpha': 0.5}, 'average_cv_score': 0.5218686955161467, 'std_dev': 0.001815925918786442}\n",
      "{'configuration': {'tfidfvectorizer__stop_words': 'english'}, 'average_cv_score': 0.5199143454315488, 'std_dev': 0.0005028856190278512}\n",
      "{'configuration': {'tfidfvectorizer__max_df': 0.3, 'tfidfvectorizer__stop_words': 'english'}, 'average_cv_score': 0.5199143454315488, 'std_dev': 0.0005028856190278512}\n",
      "{'configuration': {'tfidfvectorizer__min_df': 5, 'tfidfvectorizer__ngram_range': (1, 2)}, 'average_cv_score': 0.5350640948551354, 'std_dev': 0.0016804241769066875}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "# Assume 'train' is your DataFrame with 'processed_text' and 'discourse_type'\n",
    "# Corrected pipeline definition\n",
    "NB_model = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "# Setup k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Define different configurations\n",
    "configurations = [\n",
    "    {},  # baseline with default parameters\n",
    "    {'tfidfvectorizer__max_df': 0.5, 'tfidfvectorizer__min_df': 1},\n",
    "    {'tfidfvectorizer__max_df': 0.7, 'tfidfvectorizer__min_df': 2},\n",
    "    {'tfidfvectorizer__ngram_range': (1, 2)},\n",
    "    {'tfidfvectorizer__ngram_range': (1, 3)},\n",
    "    {'multinomialnb__alpha': 0.5},\n",
    "    {'multinomialnb__alpha': 1.0},\n",
    "    {'tfidfvectorizer__ngram_range': (1, 2), 'multinomialnb__alpha': 0.5},\n",
    "    {'tfidfvectorizer__stop_words': 'english'},\n",
    "    {'tfidfvectorizer__max_df': 0.3, 'tfidfvectorizer__stop_words': 'english'},\n",
    "    {'tfidfvectorizer__min_df': 5, 'tfidfvectorizer__ngram_range': (1, 2)}\n",
    "]\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in configurations:\n",
    "    # Create the pipeline with the current configuration\n",
    "    NB_model.set_params(**config)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(NB_model, train['processed_text'], train['discourse_type'], cv=kf)\n",
    "\n",
    "    # Record the results\n",
    "    results.append({\n",
    "        'configuration': config,\n",
    "        'average_cv_score': np.mean(cv_scores),\n",
    "        'std_dev': np.std(cv_scores)\n",
    "    })\n",
    "\n",
    "# Print or analyze the results list to see how each configuration performed\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b8db40",
   "metadata": {},
   "source": [
    "# 2. Word Embedding and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a50162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xgBoost = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "887febde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/pratikhotchandani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'discourse_text' is the column with text data\n",
    "\n",
    "# Preprocess and tokenize the text data\n",
    "# Here's a simple tokenizer function using NLTK\n",
    "def tokenize_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "    return tokenized_sentences\n",
    "\n",
    "# Apply the tokenizer to your text data\n",
    "tokenized_data = train_xgBoost['discourse_text'].apply(tokenize_text).tolist()\n",
    "\n",
    "# Flatten the list of tokenized sentences\n",
    "tokenized_data = [sentence for sublist in tokenized_data for sentence in sublist]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = gensim.models.Word2Vec(tokenized_data, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Save the model for later use\n",
    "model.save(\"word2vec_model.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f29eb9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the Word2Vec model\n",
    "model = Word2Vec.load(\"word2vec_model.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac4ecee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating feature vectors using the model \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Function to create a feature vector for an essay\n",
    "def essay_to_vector(essay, word2vec_model):\n",
    "    words = word_tokenize(essay)\n",
    "    word_vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(word2vec_model.vector_size)  # Return a zero vector if essay contains no known words\n",
    "    else:\n",
    "        return np.mean(word_vectors, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d111b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preparing data for XgBoost model\n",
    "\n",
    "\n",
    "# Vectorize each essay\n",
    "X = np.array([essay_to_vector(essay, model) for essay in train_xgBoost['discourse_text']])\n",
    "y = np.array(train_xgBoost['discourse_type'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "036df1ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "               Claim       0.62      0.77      0.68     10059\n",
      "Concluding Statement       0.50      0.12      0.20      2710\n",
      "        Counterclaim       0.65      0.09      0.16      1157\n",
      "            Evidence       0.59      0.85      0.69      9010\n",
      "                Lead       0.67      0.07      0.13      1850\n",
      "            Position       0.67      0.49      0.56      3183\n",
      "            Rebuttal       0.68      0.02      0.05       890\n",
      "\n",
      "            accuracy                           0.61     28859\n",
      "           macro avg       0.62      0.34      0.35     28859\n",
      "        weighted avg       0.61      0.61      0.55     28859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## training XgBoost classifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Label Encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder to your labels\n",
    "label_encoder.fit(train_xgBoost['discourse_type'])\n",
    "\n",
    "# Transform labels to numerical values\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "# Create DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train_encoded)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test_encoded)\n",
    "\n",
    "# Define XGBoost parameters\n",
    "params = {\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(label_encoder.classes_)\n",
    "}\n",
    "epochs = 10  # The number of training iterations\n",
    "\n",
    "# Train the model\n",
    "bst = xgb.train(params, dtrain, epochs)\n",
    "\n",
    "# Predictions\n",
    "predictions = bst.predict(dtest)\n",
    "\n",
    "# Convert predictions back to original labels\n",
    "predictions = label_encoder.inverse_transform(predictions.astype(int))\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e1af31",
   "metadata": {},
   "source": [
    "## 2. Abalation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58132096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim: {'precision': 0.6210161797799201, 'recall': 0.7749027853562529, 'f1-score': 0.6894726265383172, 'support': 10041.6}\n",
      "Concluding Statement: {'precision': 0.5148749011603659, 'recall': 0.12462061979199199, 'f1-score': 0.20057645880491157, 'support': 2701.0}\n",
      "Counterclaim: {'precision': 0.6326493109399516, 'recall': 0.0813708656432635, 'f1-score': 0.1440672602219602, 'support': 1163.4}\n",
      "Evidence: {'precision': 0.5926929531239493, 'recall': 0.8429087391478175, 'f1-score': 0.6959856590429624, 'support': 9140.4}\n",
      "Lead: {'precision': 0.6706809003743406, 'recall': 0.07318705365045305, 'f1-score': 0.1319577428095668, 'support': 1861.0}\n",
      "Position: {'precision': 0.6562246501708391, 'recall': 0.48871827304396165, 'f1-score': 0.5601759576959247, 'support': 3083.8}\n",
      "Rebuttal: {'precision': 0.7498215129575578, 'recall': 0.022911825332847396, 'f1-score': 0.04438165542054256, 'support': 867.4}\n",
      "accuracy: 0.6091702458994451\n",
      "macro avg: {'precision': 0.6339943440724178, 'recall': 0.34408859456665547, 'f1-score': 0.35237390864774076, 'support': 28858.6}\n",
      "weighted avg: {'precision': 0.6134396228392803, 'recall': 0.6091702458994451, 'f1-score': 0.5546345916996148, 'support': 28858.6}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X and y are your features and labels\n",
    "\n",
    "# Initialize the Label Encoder and fit it to your labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Define XGBoost parameters\n",
    "params = {\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(label_encoder.classes_)\n",
    "}\n",
    "epochs = 10  # The number of training iterations\n",
    "\n",
    "# Set up K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store the results of each fold\n",
    "fold_results = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "\n",
    "    # Create DMatrix for XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # Train the model\n",
    "    bst = xgb.train(params, dtrain, epochs)\n",
    "\n",
    "    # Predictions\n",
    "    predictions = bst.predict(dtest)\n",
    "\n",
    "    # Convert predictions and true labels back to original labels\n",
    "    predictions = label_encoder.inverse_transform(predictions.astype(int))\n",
    "    y_test_original = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "    # Evaluation\n",
    "    fold_results.append(classification_report(y_test_original, predictions, output_dict=True))\n",
    "\n",
    "\n",
    "# Aggregate and print results from each fold\n",
    "avg_results = {}\n",
    "\n",
    "# Initialize average results\n",
    "for key in fold_results[0].keys():\n",
    "    if isinstance(fold_results[0][key], dict):\n",
    "        avg_results[key] = {k: 0 for k in fold_results[0][key]}\n",
    "    else:\n",
    "        avg_results[key] = 0\n",
    "\n",
    "# Aggregate results\n",
    "for result in fold_results:\n",
    "    for key, value in result.items():\n",
    "        if isinstance(value, dict):\n",
    "            for sub_key in value:\n",
    "                avg_results[key][sub_key] += value[sub_key]\n",
    "        else:\n",
    "            avg_results[key] += value\n",
    "\n",
    "# Calculate the average\n",
    "for key, value in avg_results.items():\n",
    "    if isinstance(value, dict):\n",
    "        for sub_key in value:\n",
    "            avg_results[key][sub_key] /= len(fold_results)\n",
    "    else:\n",
    "        avg_results[key] /= len(fold_results)\n",
    "\n",
    "# Print or analyze the average results\n",
    "for key, value in avg_results.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90a160fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dq/pg0mssxn6yzdwtcdrwnt0bs80000gn/T/ipykernel_4640/3323767693.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters found: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    820\u001b[0m                     )\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    823\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1488\u001b[0m             )\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1491\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1919\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the Label Encoder and fit it to your labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Define a parameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 6, 8],\n",
    "    'learning_rate': [0.1, 0.01, 0.05],  # 'eta' in native XGBoost\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.5, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.3, 0.7, 1.0],\n",
    "    'gamma': [0, 0.1, 0.5],\n",
    "    # Other parameters can be added here\n",
    "}\n",
    "\n",
    "# Create the XGBClassifier\n",
    "xgb_model = XGBClassifier(objective='multi:softmax', num_class=len(label_encoder.classes_))\n",
    "\n",
    "# Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X, y_encoded)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e5f55",
   "metadata": {},
   "source": [
    "# Part 2. Predicting Effective Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f285a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effectiveness = pd.read_csv(\"/Users/pratikhotchandani/Downloads/Github/ArguSense/input/argument-effectiveness/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64884395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36760</th>\n",
       "      <td>9f63b687e76a</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>For many people they don't like only asking on...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36761</th>\n",
       "      <td>9d5bd7d86212</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>also people have different views and opinions ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36762</th>\n",
       "      <td>f1b78becd573</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>Advice is something that can impact a persons ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36763</th>\n",
       "      <td>cc184624ca8e</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>someone can use everything that many people sa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Ineffective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36764</th>\n",
       "      <td>c8a973681feb</td>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>In conclusion asking for an opinion can be ben...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Ineffective</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36765 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       discourse_id      essay_id  \\\n",
       "0      0013cc385424  007ACE74B050   \n",
       "1      9704a709b505  007ACE74B050   \n",
       "2      c22adee811b6  007ACE74B050   \n",
       "3      a10d361e54e4  007ACE74B050   \n",
       "4      db3e453ec4e2  007ACE74B050   \n",
       "...             ...           ...   \n",
       "36760  9f63b687e76a  FFA381E58FC6   \n",
       "36761  9d5bd7d86212  FFA381E58FC6   \n",
       "36762  f1b78becd573  FFA381E58FC6   \n",
       "36763  cc184624ca8e  FFA381E58FC6   \n",
       "36764  c8a973681feb  FFA381E58FC6   \n",
       "\n",
       "                                          discourse_text  \\\n",
       "0      Hi, i'm Isaac, i'm going to be writing about h...   \n",
       "1      On my perspective, I think that the face is a ...   \n",
       "2      I think that the face is a natural landform be...   \n",
       "3      If life was on Mars, we would know by now. The...   \n",
       "4      People thought that the face was formed by ali...   \n",
       "...                                                  ...   \n",
       "36760  For many people they don't like only asking on...   \n",
       "36761  also people have different views and opinions ...   \n",
       "36762  Advice is something that can impact a persons ...   \n",
       "36763  someone can use everything that many people sa...   \n",
       "36764  In conclusion asking for an opinion can be ben...   \n",
       "\n",
       "             discourse_type discourse_effectiveness  \n",
       "0                      Lead                Adequate  \n",
       "1                  Position                Adequate  \n",
       "2                     Claim                Adequate  \n",
       "3                  Evidence                Adequate  \n",
       "4              Counterclaim                Adequate  \n",
       "...                     ...                     ...  \n",
       "36760                 Claim                Adequate  \n",
       "36761                 Claim                Adequate  \n",
       "36762              Position                Adequate  \n",
       "36763              Evidence             Ineffective  \n",
       "36764  Concluding Statement             Ineffective  \n",
       "\n",
       "[36765 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cd467ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adequate       20977\n",
       "Effective       9326\n",
       "Ineffective     6462\n",
       "Name: discourse_effectiveness, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_effectiveness.discourse_effectiveness.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb38ae",
   "metadata": {},
   "source": [
    "### TF IDF and Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c1bf416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import classification_report, log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6d6a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X_text = df_effectiveness['discourse_text']\n",
    "X_type = df_effectiveness[['discourse_type']]\n",
    "y = df_effectiveness['discourse_effectiveness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "192661be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing and TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer()\n",
    "X_text_tfidf = tfidf.fit_transform(X_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "904fb36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot Encoding for discourse type\n",
    "one_hot = OneHotEncoder()\n",
    "X_type_encoded = one_hot.fit_transform(X_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76992bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine TF-IDF features with one-hot encoded features\n",
    "X_combined = hstack([X_text_tfidf, X_type_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4eb5513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a36da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6da13e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.97      0.75      4246\n",
      "           1       0.78      0.22      0.35      1825\n",
      "           2       0.69      0.03      0.06      1282\n",
      "\n",
      "    accuracy                           0.62      7353\n",
      "   macro avg       0.69      0.41      0.38      7353\n",
      "weighted avg       0.67      0.62      0.53      7353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes Classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fbb9ad15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss:  0.935849988976215\n"
     ]
    }
   ],
   "source": [
    "# To compute log-loss, we need the probabilities of each class\n",
    "y_pred_proba = nb_classifier.predict_proba(X_test)\n",
    "\n",
    "# Calculate and print log-loss\n",
    "logloss = log_loss(y_test, y_pred_proba)\n",
    "print(\"Log-loss: \", logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d189567a",
   "metadata": {},
   "source": [
    "## Word2Vec and XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28ed5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a1950369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Word2Vec model\n",
    "word2vec_model = gensim.models.Word2Vec.load(\"word2vec_model.model\")\n",
    "\n",
    "# Function to convert text to Word2Vec vector\n",
    "def text_to_word2vec(text, model):\n",
    "    words = text.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    else:\n",
    "        return np.mean(word_vectors, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fbe4d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X_text = df_effectiveness['discourse_text'].apply(lambda x: text_to_word2vec(x, word2vec_model))\n",
    "X_type = df_effectiveness[['discourse_type']]\n",
    "y = df_effectiveness['discourse_effectiveness']\n",
    "\n",
    "# One-hot Encoding for discourse type\n",
    "one_hot = OneHotEncoder()\n",
    "X_type_encoded = one_hot.fit_transform(X_type).toarray()\n",
    "\n",
    "# Combine Word2Vec features with one-hot encoded features\n",
    "X_combined = np.hstack([np.array(X_text.tolist()), X_type_encoded])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "233675e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad2feb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57401146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.85      0.74      4246\n",
      "           1       0.65      0.50      0.56      1825\n",
      "           2       0.51      0.19      0.27      1282\n",
      "\n",
      "    accuracy                           0.65      7353\n",
      "   macro avg       0.60      0.51      0.53      7353\n",
      "weighted avg       0.63      0.65      0.61      7353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost Classifier\n",
    "xgb_classifier = XGBClassifier()\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dd3c7df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss:  0.8042073505316307\n"
     ]
    }
   ],
   "source": [
    "# To compute log-loss, we need the probabilities of each class\n",
    "y_pred_proba_xgb = xgb_classifier.predict_proba(X_test)\n",
    "\n",
    "# Calculate and print log-loss\n",
    "logloss = log_loss(y_test, y_pred_proba_xgb)\n",
    "print(\"Log-loss: \", logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920b1a5a",
   "metadata": {},
   "source": [
    "# K fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c7618f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best cross-validation score:  0.646946858966901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.87      0.75      4246\n",
      "           1       0.67      0.50      0.57      1825\n",
      "           2       0.56      0.15      0.24      1282\n",
      "\n",
      "    accuracy                           0.65      7353\n",
      "   macro avg       0.63      0.51      0.52      7353\n",
      "weighted avg       0.64      0.65      0.61      7353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'n_estimators': [100, 200],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Create the XGBClassifier instance\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')  # Adjust eval_metric for your task\n",
    "\n",
    "# Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the Grid Search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd2f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
